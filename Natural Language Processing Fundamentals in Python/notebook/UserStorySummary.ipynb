{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Text Preprocessing Pkg\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "\n",
    "def text_summarizer(raw_docx):\n",
    "    raw_text = raw_docx\n",
    "    docx = nlp(raw_text)\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    # Build Word Frequency\n",
    "# word.text is tokenization in spacy\n",
    "    word_frequencies = {}  \n",
    "    for word in docx:  \n",
    "        if word.text not in stopwords:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1\n",
    "\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    # Sentence Tokens\n",
    "    sentence_list = [ sentence for sentence in docx.sents ]\n",
    "\n",
    "    # Calculate Sentence Score and Ranking\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if len(sent.text.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
    "\n",
    "    # Find N Largest\n",
    "    summary_sentences = nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "    return summary_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize \n",
    "from gensim.summarization import keywords \n",
    "\n",
    "#Give User story as per yours\n",
    "raw_text = \"\\\"As a [persona]\\\": Who are we building this for? We’re not just after a job title, we’re after the persona of the person. Max. Our team should have a shared understanding of who Max is. We’ve hopefully interviewed plenty of Max’s. We understand how that person works, how they think and what they feel. We have empathy for Max.\\r\\n“Wants to”: Here we’re describing their intent — not the features they use. What is it they’re actually trying to achieve? This statement should be implementation free — if you’re describing any part of the UI and not what the user goal is you\\'re missing the point.\\r\\n“So that”: how does their immediate desire to do something this fit into their bigger picture? What’s the overall benefit they’re trying to achieve? What is the big problem that needs solving?\"\n",
    "\n",
    "#Overview\n",
    "res_summary = summarize(raw_text, ratio = 0.3)\n",
    "print ('\\033[1m' + 'Overview:' +'\\033[0m')\n",
    "print(res_summary+'\\n')\n",
    "\n",
    "print ('\\033[1m' + 'Dependencies:'+'\\033[0m')\n",
    "print('Automation/Manual')\n",
    "\n",
    "#Story Ac\n",
    "print ('\\n\\033[1m' + 'Acceptence Criteria:'+'\\033[0m')\n",
    "summary_sentences = text_summarizer(raw_text)\n",
    "final_sentences = [ w.text for w in summary_sentences ]\n",
    "\n",
    "for i in range(len(final_sentences)): \n",
    "    print (i, end = \". \") \n",
    "    print (final_sentences[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

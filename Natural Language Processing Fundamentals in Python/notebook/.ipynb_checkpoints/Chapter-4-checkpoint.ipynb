{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Chapter-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying fake news using supervised learning with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer for text classification\n",
    "It's time to begin building your text classifier! The data has been loaded into a DataFrame called df. Explore it in the IPython Shell to investigate what columns you can use. The .head() method is particularly informative.\n",
    "\n",
    "In this exercise, you'll use pandas alongside scikit-learn to create a sparse text vectorizer you can use to train and test a simple supervised model. To begin, you'll set up a CountVectorizer and investigate some of its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "df = pd.read_csv('datasets/News Classifier/fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary’s Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n",
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"],y,test_size=0.33,random_state=53)\n",
    "\n",
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data using only the 'text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer for text classification\n",
    "Similar to the sparse CountVectorizer created in the previous exercise, you'll work on creating tf-idf vectors for your documents. You'll set up a TfidfVectorizer and investigate some of its features.\n",
    "\n",
    "In this exercise, you'll use pandas and sklearn along with the same X_train, y_train and X_test, y_test DataFrames and Series you created in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
      "  (1, 42470)\t0.07711040274149526\n",
      "  (1, 12105)\t0.15008066461476866\n",
      "  (1, 54177)\t0.13782629144711137\n",
      "  (1, 50628)\t0.061296988343109586\n",
      "  (1, 15924)\t0.3479045460649079\n",
      "  (1, 44520)\t0.4973826512693341\n",
      "  (1, 51896)\t0.11596517664605868\n",
      "  (1, 35783)\t0.30902690818827977\n",
      "  (1, 35256)\t0.12628385718450857\n",
      "  (1, 21881)\t0.21271688045815978\n",
      "  (1, 42534)\t0.06081715886809217\n",
      "  (1, 8399)\t0.08729542880625335\n",
      "  (1, 29531)\t0.1454406205718245\n",
      "  (1, 15927)\t0.4973826512693341\n",
      "  (1, 25686)\t0.13550453594288983\n",
      "  (1, 49203)\t0.1672740861784377\n",
      "  (1, 16814)\t0.10404977746548139\n",
      "  (1, 36087)\t0.12648679854389897\n",
      "  (1, 21568)\t0.1007920919566398\n",
      "  (1, 25684)\t0.1030420922189754\n",
      "  (1, 38823)\t0.06048803110658644\n",
      "  (1, 47506)\t0.14539060877460044\n",
      "  (1, 36831)\t0.10772488937433067\n",
      "  (2, 16972)\t0.1606296088662543\n",
      "  (2, 762)\t0.48803966069171073\n",
      "  :\t:\n",
      "  (4, 19325)\t0.05452053080897492\n",
      "  (4, 7259)\t0.06755319386644243\n",
      "  (4, 51456)\t0.06475353785981061\n",
      "  (4, 7426)\t0.06511222583761835\n",
      "  (4, 39829)\t0.05465988305311523\n",
      "  (4, 9486)\t0.0498567667112753\n",
      "  (4, 27568)\t0.028302541956335657\n",
      "  (4, 48702)\t0.1743065129793454\n",
      "  (4, 41541)\t0.03347420115927609\n",
      "  (4, 20268)\t0.040257433434577744\n",
      "  (4, 44567)\t0.04521244574721562\n",
      "  (4, 7184)\t0.04119900385804159\n",
      "  (4, 15056)\t0.06406962747278261\n",
      "  (4, 23980)\t0.040601095306683384\n",
      "  (4, 36845)\t0.03921825297423197\n",
      "  (4, 37249)\t0.04750657931325537\n",
      "  (4, 12692)\t0.0406789533096042\n",
      "  (4, 43655)\t0.07010870747834863\n",
      "  (4, 4093)\t0.059095267180806606\n",
      "  (4, 26966)\t0.031877860469596585\n",
      "  (4, 9120)\t0.02872653761009892\n",
      "  (4, 5676)\t0.059095267180806606\n",
      "  (4, 22019)\t0.07963078672826533\n",
      "  (4, 43462)\t0.12234830953369169\n",
      "  (4, 23468)\t0.03469208821573642\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
